{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjclx1ixn8rI"
      },
      "source": [
        "# S3 and boto3\n",
        "\n",
        "This small step by step tutorial will guide you to:\n",
        "\n",
        "- Create an AWS account\n",
        "- Create an Amazon S3 bucket\n",
        "- Download and configure the AWS CLI\n",
        "- Make public the files in the bucket\n",
        "- Upload your files\n",
        "- Download the files from the bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka4p27jen8rM"
      },
      "source": [
        "## Create an S3 Bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gg6bLB9n8rN"
      },
      "source": [
        "Amazon Simple Storage Service (Amazon S3) buckets are data lakes where you can store your files. To know more about data lakes check this [website](https://en.wikipedia.org/wiki/Data_lake)\n",
        "\n",
        "S3 buckets allow you to store up to 5Gb for free, and after that $0.023 per Gb. Take a look at this [page](https://aws.amazon.com/es/s3/pricing/?nc=sn&loc=4) to know more about the S3 pricing.\n",
        "\n",
        "Let's create an S3 bucket to upload our files. First, go to the AWS [dashboard](https://aws.amazon.com). In the search bar, type 'S3', and click on the first option:\n",
        "<p align=\"center\"> \n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/aws_search_S3.png?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "In the next window, click on 'Create bucket':\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/create_bucket_button.png?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "Set a name for your bucket, and choose a region; any region from the US usually works fine, but make sure to use the same region in the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHO2JkwZn8rN"
      },
      "source": [
        "## Create an IAM user "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjArnN7cn8rO"
      },
      "source": [
        "We need to create an Isentity and Access Management (IAM) user to provide the necessary credentials that allow us to interact with the AWS resources.\n",
        "\n",
        "To create an IAM user, go to the AWS dashboard, and, in the search bar, look for \"IAM\" and click the first option:\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/IAM.png?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "Next, click User in the left-hand side, and then click 'Add User'\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/IAM_User.png?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "Then fill the user name with the name you want, tick programmatic access, and click Next\n",
        "\n",
        "In the permissions page, select Attach existing policies directly, tick the AdministratorAccess and then click Next:\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/Policies.png?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "On the next pages, simply click Next and create the user. You will see the next page. This page contains your credentials for connecting to your S3 bucket. These credentials will only show once, so make sure to download the .csv file:\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/Credentials.png?raw=1\" width=\"500\"/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvqtH5U5n8rP"
      },
      "source": [
        "## Download and configure AWS CLI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZhQ7Jdqn8rP"
      },
      "source": [
        "To communicate your computer with your AWS resources, you need to provide the right configurations. The \"awscli\" package allows us to easily configure the environment variables our computer needs to connect to our AWS services\n",
        "\n",
        "Let's install awscli using:\n",
        "`pip install awscli`\n",
        "\n",
        "Next, in the terminal type `aws configure`\n",
        "Enter the information as it appears in the .csv file you downloaded in the previous step. \n",
        "\n",
        "When you are asked about the region name, go to your S3 bucket and look at the AWS Region of your bucket. The region name looks something like 'us-east-1'\n",
        "\n",
        "When asked about the output format, you can skip this info by pressing enter.\n",
        "\n",
        "Now, your computer is ready to use boto3\n",
        "\n",
        "<details>\n",
        "  <summary> <font size=+1> Note if you are on Google Colab </font></summary>\n",
        "  \n",
        "  If you are using Google Colab, you need to install the awscli as you would do in your local machine. The only difference is that the configuration won't be stored in your next sessions.\n",
        "  \n",
        "  To install awscli, type `!pip install awscli` in a new cell.\n",
        "  \n",
        "  Then, in the terminal type `!aws configure` and follow the instructions above\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbj2ox3Tn8rQ"
      },
      "source": [
        "\n",
        "Test that your installation is working by using `aws s3 ls`. You should see something like this:\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/AWSCLI_ls.png?raw=1\" width=\"500\"/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suesy0Ren8rQ"
      },
      "source": [
        "# Using boto3 for using your AWS resources from Python\n",
        "\n",
        "boto3 is a library that allows us to work with AWS from our python script. In this example we are going to simply upload, download and explore S3 buckets, but you can use it to manage other resources such as `EC2`, `RDS`, and `DynamoDB`. You can check boto3's documentation [here](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
        "\n",
        "First of all, install boto3 by typing in the terminal `pip install boto3`. Take into account that, in order to use `boto3` you need to have aws configured as we did above.\n",
        "\n",
        "Let's start by telling to boto3 that we want to use an S3 bucket:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7DzIuBpn8rR"
      },
      "outputs": [],
      "source": [
        "import boto3 \n",
        "s3_client = boto3.client('s3')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AKdHBa_n8rS"
      },
      "source": [
        "\n",
        "Now, let's upload something to your bucket:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2xmDeC0n8rS"
      },
      "outputs": [],
      "source": [
        "# response = s3_client.upload_file(file_name, bucket, object_name)\n",
        "response = s3_client.upload_file('cat_0.jpg', 'cat-scraper', 'cat.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMPjTiuZn8rT"
      },
      "source": [
        "\n",
        "*file_name* is the directory of the file you want to upload, *bucket* is the name of your S3 bucket, and *object_name* is the name you want to give to your file once uploaded\n",
        "\n",
        "\n",
        "Try it yourself!\n",
        "\n",
        "Now, let's see the content of the bucket:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWOX-8Vln8rT"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "s3 = boto3.resource('s3')\n",
        "\n",
        "my_bucket = s3.Bucket('pokemon-sprites')\n",
        "\n",
        "for file in my_bucket.objects.all():\n",
        "    print(file.key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii10OpRgn8rT"
      },
      "source": [
        "\n",
        "\n",
        "Once you know the content of it, you can download the files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI_iZQAqn8rT"
      },
      "outputs": [],
      "source": [
        "s3 = boto3.client('s3')\n",
        "\n",
        "# Of course, change the names of the files to match your own.\n",
        "s3.download_file('pokemon-sprites', 'zubat/front.png', 'zubat.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWz_ACJGn8rU"
      },
      "source": [
        "# Make the files public"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrkI5Hnfn8rU"
      },
      "source": [
        "\n",
        "In your S3 bucket, disable the 'Block all public access' option:\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/disable.PNG?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "Once you created it, you can access to it in the bucket list, now you just need to make it public.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-y8V3RXn8rU"
      },
      "source": [
        "\n",
        "\n",
        "To make the objects public, go to http://awspolicygen.s3.amazonaws.com/policygen.html, which will help you create the necessary policy.<br>\n",
        "- In 'Select Type of Policy' select S3 Bucket Policy. \n",
        "- In 'Principal' type ' * '\n",
        "- In 'Actions' select 'Get Object'\n",
        "- In 'Amazon Resource Name (ARN)' type arn:aws:s3:::{your_bucket_name}/*\n",
        "- Press Statement\n",
        "- Press Generate Policy and copy the text\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/Policy_public.png?raw=1\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "Go back to your bucket and go to the Permissions tab. In 'Bucket Policy' click Edit. Paste the text you copied and save changes.<br> \n",
        "Now your bucket is publicly accesible, and anyone can download your files. \n",
        "\n",
        "In your bucket, select the file you want to download, and copy the Object URL.\n",
        "\n",
        "<p align=\"center\"> <img src=\"https://github.com/life-efficient/Data-Engineering/blob/main/6.%20Essential%20Cloud%20Technology/2.%20S3%20and%20boto3/images/URL_public.png?raw=1\" width=\"500\"></p>\n",
        "\n",
        "Open a python editor or notebook and use the requests library to download the image from the URL you just copied. Something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKr7qIPdn8rU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "# Change this with your URL\n",
        "url = 'https://pokemon-sprites.s3.amazonaws.com/blastoise/front.png'\n",
        "\n",
        "response = requests.get(url)\n",
        "with open('blastoise.png', 'wb') as f:\n",
        "    f.write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAUdC4nYn8rV"
      },
      "source": [
        "\n",
        "\n",
        "And that's it! you should be able to see the file in the same working directory."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Notebook.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}