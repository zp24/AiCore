{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import tempfile\n",
    "import sqlalchemy #create an engine which connects local machine/python script with database\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "client = boto3.client('s3')\n",
    "bucket = os.environ.get('DB_BUCKET')\n",
    "sourcepath = \"images\"\n",
    "source = os.listdir(sourcepath)\n",
    "\n",
    "for file in source:\n",
    "    '''\n",
    "     specify location of files in images directory, otherwise it will try to look \n",
    "     for images in current working directory\n",
    "    '''\n",
    "\n",
    "    with open(f'images/{file}', \"rb\") as f: #ensures each file is looked at individually \n",
    "       client.upload_fileobj(f, bucket, file)\n",
    "        \n",
    "    #print(file)\n",
    "#source[0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy #create an engine which connects local machine/python script with database\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "DBAPI = 'psycopg2' #database API - API to connect Python with database\n",
    "#use AWS details to connect database\n",
    "HOST = os.environ.get('DB_HOST') #endpoint\n",
    "USER = os.environ.get('DB_USER')\n",
    "PASSWORD = os.environ.get('DB_PASS')\n",
    "DATABASE = 'postgres'\n",
    "PORT = 5432\n",
    "\n",
    "engine = create_engine(f'{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris #sklearn is a machine learning database\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.to_sql = ('iris','engine','')\n",
    "'''table name to store dataframe, engine created to communicate between database and python, \n",
    "    if table already exists, replace or append (optional)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscraper import Scraper\n",
    "\n",
    "scraper = Scraper() #call scraper class\n",
    "scraper.accept_cookies()\n",
    "scraper.search_bar('Kingdom Hearts') #add search keyword here\n",
    "container = scraper.find_container()\n",
    "scraper.collect_page_links()\n",
    "src = scraper.find_images(container= container)\n",
    "scraper.upload_images(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium.webdriver import Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager #installs Chrome webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import boto3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "for link in scraper.link_list[0:1]: #obtain image from first link only\n",
    "    scraper.driver.get(link)\n",
    "    time.sleep(2)\n",
    "    image = \"test.png\"\n",
    "    with open(image, \"wb\") as file: #wb = write and binary mode\n",
    "        img = scraper.driver.find_element(By.XPATH, \n",
    "                    '//img[@class=\"boxshot lazyloaded\"]')\n",
    "                #//*[@id=\"main-content\"]/article/div[1]/div/div[1]/div[2]/figure/img\n",
    "        file.write(img.screenshot_as_png)\n",
    "        bucket = os.environ.get('DB_BUCKET')\n",
    "        \n",
    "        DATABASE_TYPE = 'postgresql'\n",
    "        DBAPI = 'psycopg2' #database API - API to connect Python with database\n",
    "        #use AWS details to connect database\n",
    "        HOST = os.environ.get('DB_HOST') #endpoint\n",
    "        USER = os.environ.get('DB_USER')\n",
    "        PASSWORD = os.environ.get('DB_PASS')\n",
    "        DATABASE = 'postgres'\n",
    "        PORT = 5432\n",
    "\n",
    "        engine = create_engine(f'{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}')\n",
    "        client.upload_file(image , bucket, 'kh.png')\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('s3')\n",
    "'''specify directory where data.json is located\n",
    "    upload_fileobj is used where the file has already been opened\n",
    "    otherwise use upload_file'''\n",
    "bucket = os.environ.get('DB_BUCKET')\n",
    "#with open(\"raw_data/data.json\", \"rb\") as file:\n",
    " #  response = client.upload_fileobj(file, bucket, \"data.json\") \n",
    "client.upload_file(\"raw_data/data.json\", bucket, \"data.json\")\n",
    "client.upload_file(\"raw_data/image_data.json\", bucket, \"image_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "#create folder in s3 bucket\n",
    "bucket = os.environ.get('DB_BUCKET')\n",
    "\n",
    "folder_name = \"images\"\n",
    "folder_name1 = \"raw_data\"\n",
    "\n",
    "s3.put_object(Bucket=bucket, Key=(folder_name+'/'))\n",
    "s3.put_object(Bucket=bucket, Key=(folder_name1+'/'))\n",
    "\n",
    "#upload files into s3 bucket folders\n",
    "client.upload_file(\"raw_data/data.json\", bucket, f\"{folder_name1}/data.json\") #saves data.json file in folder\n",
    "client.upload_file(\"raw_data/image_data.json\", bucket, f\"{folder_name1}/image_data.json\")\n",
    "\n",
    "sourcepath = \"images\"\n",
    "source = os.listdir(sourcepath)\n",
    "\n",
    "for file in source:\n",
    "    with open(f'images/{file}', \"rb\") as f: \n",
    "       '''specify location of files in images directory, otherwise it will try to look \n",
    "            for images in current working directory'''\n",
    "       client.upload_fileobj(f, bucket, f'{folder_name}/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscraper import Scraper\n",
    "scraper = Scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data.json as pandas dataframe and sql table\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "with open('raw_data/data.json') as json_file:\n",
    "    data = json.load(json_file) #load json file\n",
    "    print(\"Type:\", type(data))\n",
    "    df_products = pd.DataFrame(data) #save data in json file in dataframe\n",
    "sql_table = df_products.to_sql(\"SE_products\", con=scraper.engine, if_exists='replace', index=False) #upload pandas dataframe to sql table \n",
    "                                                                                                   #use replace instead of append if changing everything in sql table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image_data.json as pandas dataframe and sql table\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "with open('raw_data/image_data.json') as json_file:\n",
    "    data = json.load(json_file) #load json file\n",
    "    print(\"Type:\", type(data))\n",
    "    df_images = pd.DataFrame(data) #save data in json file in dataframe\n",
    "sql_table_i = df_images.to_sql(\"SE_product_images\", con=scraper.engine, if_exists='replace', index=False) #upload pandas dataframe to sql table \n",
    "                                                                                                   #use replace instead of append if changing everything in sql table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sourcepath = \"images\"\n",
    "source = os.listdir(sourcepath)\n",
    "bucket = os.environ.get('DB_BUCKET')\n",
    "\n",
    "image_list = []\n",
    "for file in source:\n",
    "    with open(f'images/{file}', \"rb\") as f: \n",
    "       '''specify location of files in images directory, otherwise it will try to look \n",
    "            for images in current working directory'''\n",
    "       images = image_list.append(file)\n",
    "       #client.upload_fileobj(f, bucket, f'{folder_name}/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products[\"Images\"] = image_list #add image to each product (numerical order, not based on id matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.sort_values(by='ID') #sort_values(by=\"ID\") will change order of products numerically (ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ID\"], image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table #prints number of entries"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96845aca18e994caba59710a135a9f2069490d583ecd78ead3231a9fecf57406"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('selenium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
